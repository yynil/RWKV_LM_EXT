import os
parent_path = os.path.dirname(os.path.dirname(os.path.realpath(__file__)))
import sys
sys.path.append(parent_path)
print(f'add path: {parent_path} to sys.path')
os.environ['RWKV_JIT_ON'] = '0'
os.environ['RWKV_T_MAX'] = '4096'
os.environ['RWKV_FLOAT_MODE'] = 'bf16'
os.environ['RWKV_HEAD_SIZE_A'] = '64'
os.environ['RWKV_T_MAX'] = '4096'
os.environ["RWKV_MY_TESTING"]='x060'
os.environ['RWKV_CTXLEN'] = '4096'
import torch
from src.model_run import RWKV,PIPELINE_ARGS,create_empty_args,load_embedding_ckpt_and_parse_args,generate
from tokenizer.rwkv_tokenizer import TRIE_TOKENIZER
        

class StatesGenerator:
    def __init__(self,base_model,tokenizer_file,device='cuda'):
        self.base_model = base_model
        args = create_empty_args()
        w = load_embedding_ckpt_and_parse_args(base_model, args)
        model = RWKV(args)
        info = model.load_state_dict(w)
        model.eval()
        self.dtype = torch.bfloat16
        self.device = device
        self.model = model.to(self.dtype).to(self.device)
        del w
        self.states = {}
        self.args = args
        self.tokenizer = TRIE_TOKENIZER(tokenizer_file)

    def load_states(self,states_file,states_name):
        args = self.args
        states = torch.load(states_file)
        states_value = []
        n_head = args.n_head
        head_size = args.head_size_a
        for i in range(args.n_layer):
            key = f'blocks.{i}.att.time_state'
            value = states[key]
            prev_x = torch.zeros(args.n_embd,device=self.device,dtype=torch.float)
            prev_states = torch.tensor(value,device=self.device,dtype=torch.float).transpose(1,2)
            prev_ffn = torch.zeros(args.n_embd,device=self.device,dtype=torch.float)
            states_value.append(prev_x)
            states_value.append(prev_states)
            states_value.append(prev_ffn)
        self.states[states_name] = states_value

    def get_states(self,states_name):
        if states_name not in self.states:
            raise None
        else:
            states_copy = []
            for s in self.states[states_name]:
                states_copy.append(s.clone())
            return states_copy


    def generate(self,input_text,instruction,states_name,temperature = 1.0, top_p = 0.96, top_k = 20, alpha_frequency = 0.25, alpha_presence = 0.25, alpha_decay = 0.996, token_ban = [], token_stop = [0,1], chunk_len = 512,gen_count=128):
        args = self.args
        model = self.model
        states = self.get_states(states_name)
        gen_args = PIPELINE_ARGS(temperature = temperature, top_p = top_p, top_k = top_k, alpha_frequency = alpha_frequency, alpha_presence = alpha_presence, alpha_decay = alpha_decay, token_ban = token_ban, token_stop = token_stop, chunk_len = chunk_len)
        cat_char = 'ğŸ±'
        bot_char = 'ğŸ¤–'
        instruction ='ä½ æ˜¯ä¸“é—¨è¿›è¡Œå…³ç³»æŠ½å–çš„ä¸“å®¶ã€‚è¯·ä»inputä¸­æŠ½å–å‡ºç¬¦åˆschemaå®šä¹‰çš„å…³ç³»ä¸‰å…ƒç»„ï¼Œä¸å­˜åœ¨çš„å…³ç³»è¿”å›ç©ºåˆ—è¡¨ã€‚è¯·æŒ‰ç…§JSONå­—ç¬¦ä¸²çš„æ ¼å¼å›ç­”ã€‚'
        ctx = f'{cat_char}:{instruction}\n{input_text}\n{bot_char}:'
        
        with torch.no_grad():
            with torch.autocast(enabled=True,device_type='cuda',dtype=self.dtype):
                output = generate(model,ctx,self.tokenizer,token_count=gen_count,args=gen_args,state=states)
        return output
    
if __name__ == '__main__':
    model_file = '/media/yueyulin/KINGSTON/models/rwkv6/RWKV-x060-World-7B-v2.1-20240507-ctx4096.pth'

    kg_states_file = '/media/yueyulin/data_4t/models/states_tuning/instructKGC_scattered/trainable_model/epoch_2/RWKV-x060-World-7B-v2.1-20240507-ctx4096.pth.pth'
    type_states_file = '/media/yueyulin/data_4t/models/states_tuning/kg_type/20240702-105004/trainable_model/epoch_2/RWKV-x060-World-7B-v2.1-20240507-ctx4096.pth.pth'
    unit_extractor_states_file = '/media/yueyulin/data_4t/models/states_tuning/units_extractor/trainable_model/epoch_2/RWKV-x060-World-7B-v2.1-20240507-ctx4096.pth.pth'
    tokenizer_file = '/home/yueyulin/github/RWKV_LM_EXT/tokenizer/rwkv_vocab_v20230424.txt'
    sg = StatesGenerator(model_file,tokenizer_file)
    sg.load_states(kg_states_file,'kg')
    sg.load_states(type_states_file,'type')
    sg.load_states(unit_extractor_states_file,'unit_extractor')
    from kg_schema import whole_schema,all_types
    import json
    kg_instruction = 'ä½ æ˜¯ä¸€ä¸ªå›¾è°±å®ä½“çŸ¥è¯†ç»“æ„åŒ–ä¸“å®¶ã€‚è¯·ä»inputä¸­æŠ½å–å‡ºç¬¦åˆschemaå®šä¹‰çš„å®ä½“å®ä¾‹å’Œå…¶å±æ€§ï¼Œä¸å­˜åœ¨çš„å±æ€§ä¸è¾“å‡ºï¼Œå±æ€§å­˜åœ¨å¤šå€¼å°±è¿”å›åˆ—è¡¨ã€‚è¯·æŒ‰ç…§JSONå­—ç¬¦ä¸²çš„æ ¼å¼å›ç­”ã€‚'
    type_instruction = 'è¯·æ ¹æ®inputä¸­çš„æ–‡æœ¬å†…å®¹ï¼Œé€‰æ‹©schemaä¸­çš„æœ€ç¬¦åˆinputå†…å®¹çš„ç±»åˆ«è¾“å‡ºï¼Œç”¨JSONæ ¼å¼è¾“å‡ºã€‚'
    text = "ä¸ªäººç®€ä»‹å§“åï¼šæ‹‰å¡Â·ç»´æ¯”  æ‰€å±çƒé˜Ÿï¼šå¸ƒä¼¦ç‰¹ç¦å¾·  å›½ç±ï¼šä¸¹éº¦ã€æ³•å›½ã€è·å…°ã€æ³•å±åœ­äºšé‚£  å‡ºç”Ÿæ—¥æœŸï¼š1987-02-22  èº«é«˜ï¼š181cm  ä½“é‡ï¼š73kg  åœºä¸Šä½ç½®ï¼šå‰é”‹  çƒè¡£å·ç ï¼š21  ä¸¹éº¦å°„æ‰‹æ‹‰å¡-ç»´æ¯”ï¼Œè·å¾—äº†2014èµ›å­£ç‘è¶…è”èµ›é‡‘é´"
    input_text = json.dumps({'input':text,'schema':all_types},ensure_ascii=False)
    print(input_text)
    type_output = sg.generate(input_text,type_instruction,'type',top_k=0,top_p=0,gen_count=10)
    print(type_output)
    # type_output = json.loads(type_output)
    schema_type = 'äººç‰©'
    print(schema_type)
    schema = whole_schema[schema_type]
    input_text = json.dumps({'input':text,'schema':schema},ensure_ascii=False)
    kg_output = sg.generate(input_text,kg_instruction,'kg',top_k=0,top_p=0,gen_count=2048)
    print(kg_output)
    kg_output = json.loads(kg_output)
    # print(kg_output['result'])

    unit_instruction = 'ä½ æ˜¯ä¸€ä¸ªå•ä½æå–ä¸“å®¶ã€‚è¯·ä»inputä¸­æŠ½å–å‡ºæ•°å­—å’Œå•ä½ï¼Œè¯·æŒ‰ç…§JSONå­—ç¬¦ä¸²çš„æ ¼å¼å›ç­”ï¼Œæ— æ³•æå–åˆ™ä¸è¾“å‡ºã€‚'
    input_text = 'å¤§çº¦503ä¸‡å¹³æ–¹ç±³'
    unit_output = sg.generate(input_text,unit_instruction,'unit_extractor',top_k=0,top_p=0,gen_count=128)
    print(unit_output)
    input_text = '4845äºº'
    unit_output = sg.generate(input_text,unit_instruction,'unit_extractor',top_k=0,top_p=0,gen_count=128)
    print(unit_output)
    input_text = 'çº¦89434æˆ·'
    unit_output = sg.generate(input_text,unit_instruction,'unit_extractor',top_k=0,top_p=0,gen_count=128)
    print(unit_output)
    input_text = 'å¯èƒ½æœ‰38.87äº¿å¹³æ–¹å…¬é‡Œ'
    unit_output = sg.generate(input_text,unit_instruction,'unit_extractor',top_k=0,top_p=0,gen_count=128)
    print(unit_output)